---
title: "Mod2_water"
output: html_document
date: "2023-11-14"
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# DRAFT: Background for Module 2: Water Quality

Water sustains life on our planet and water is sacred to Native Americans. "Water quality" captures many components of the chemistry, biology, and physics of fresh water. In this module, we will study data about two of these components, water temperature (T) and dissolved oxygen (DO). 

Bull trout are a culturally important, but threatened species of fish native to the U.S. Northwest and the Canadian Rockies. They provide an example of how water quality affects Indigenous culture, because they require water temperatures below XX degrees centigrade and 


VIGNETTE OUTLINE:
Set up: 
- Bull trout: culturally important and threatened species.
- Thresholds of low D.O. and high T that are dangerous for bull trout (from lit)
- Goal: Picking between 2 streams for trout introduction.
-- Stream A is fed by a nearby groundwater spring.
-- Stream B is outflow from a mountain lake. 


-------
Notes from JMc to Catherine about data:  
Overall Data qualities: 
(1) We should have average *annual* T and DO data (because Temp and DO will cycle seasonally, which will both make these data harder to simulate and also be more difficult to visualize trends over time)
(2) Stream A should have a shorter observational length (like 2012 - 2022), than Stream B (say 2007 - 2022). This is because we want some NA values that we will learn to delete later.]
(3) The data should be in wide form (described in summary below), which will allow us to "tidy" the data by pivoting to long form data.

Stream A Data qualities: 
D.O. is on the low side (occasionally sneaking into the danger zone), but Temp is OK. No trend in either, because the groundwater spring keeps Temp stable, and DO is a function of Temp.

Stream B Data qualities: 
On average, D.O. and Temp are better than Stream A, but the trend is towards higher T and lower D.O. (because climate change is warming the lake water and D.O. declines as T increases)

Summary of fake data set:
- 5 Columns: headings are "Year", "StreamA_Temperature". "StreamA_DO", "StreamB_Temperature". "StreamB_DO"
- 15 Rows: 2007 to 2022
- Values are as described above, with NA for Stream A from 2007 to 2011
-------

Overview of upcoming steps:
1. Import data, pivot to tidier long format & removing NAs, Calculate summary stats for both sites. Q: Which site looks better? A: Site B, because it has higher D.O. and lower T.
2. Make a scatter plot of Temp & D.O. from both sites. Plot sites with different colors. Add lines (or overlay a box) identifying the T and D.O. thresholds. Q: Which site looks better? A: Site B, again, because more points are outside of the "danger zone."
3. Now let's make a new kind of graph: time series of changing T and D.O. from the two sites. First graph is Temperature from both sites. Second graph is DO from both sites (use the same colors for each site as in step 2). NOTE: THIS IS REVISED FROM 11/20: AVOID THE DOUBLE AXIS COMPLICATIONS AND EASIER TO COMPARE TRENDS ACROSS SITES.
Place graphs side-by-side. Q: Which site looks better now? A: Maybe Site A, because even though it has more days when the water quality dips into the danger zone, it's not getting worse. Site B is better for now, but climate change seems to be moving it into  more unhealthy conditions.


In this module, there are four main coding goals: 
1. We will explore how water quality data can help communities make decisions to protect culturally important species.
2. We will learn how to rearrange data into a "tidy" format that makes graphing easier and we will learn how to "debug" code, in other words, we'll learn how to fix common problems that we see when using real world data. 
3. We will learn how to separate data into meaningful categories in R based on 
similarities. This is known as subsetting. 
4. We will learn how to make graphs of data over time. These are called "time series" graphs.

--------------------------------------------------------------------------------
#INSTRUCTOR'S VERSION: Learning goals 

1. Students will review the steps to set a working directory and load in data from 
an extrenal data file. 

2. Students will review basic commands in R to explore their data before they 
begin to analyze it. 

3. Students will review how to load in packages. 

4. NEW SKILL: Students will learn how to reformat data (in this case from "wide form" data to "long form" data). This is an example of data wrangling, an important step in data science.

5. Students will review basic summary statistic commands in R to pull the mean, 
median, max, and min values for different variables in the data set. 

6. NEW SKILL: students will learn how to handle common code bugs, such as NAs. 

7. NEW SKILL: students will learn how to subset data in R based on scientifically 
relevant groups. 

7. Students will review how to make a scatter plot graph using ggplot. 

8. NEW SKILL: Students will learn how to make a new kind of plot in ggplot (a time-series line graph), This will be framed to show how data presentation can help communities make decisions about trends over time.

--------------------------------------------------------------------------------
#PART 1: Loading in and exploring the data 

Like we did in Module 1, before we being to analyze our data, we need to do a few
steps first.

#Clearing Environment 

Before we start to do anything in R, we should clear our environment. As a reminder,
your environment is where R stores all the objects and data you were working with
since the last time you worked in R. See the code chunk below on how to clear 
your environment. 

```{r}
rm(list = ls())
```


#Setting the Working Directory 

We will now set our working directory. As you may remember, setting our working 
directory tells R where to find the files we want to work with on our computer. 

[JMc comment: We should decide as a class whether we want to set working directories this way, or just put the data files in the same directory as this .Rmd file. When you knit an R Markdown it looks for the data in that directory.
See this link, too: https://github.com/yihui/knitr/issues/277#issuecomment-6528846
]


```{r}
current_path = rstudioapi::getActiveDocumentContext()$path
setwd(dirname(current_path))
```


#Load in packages 

Next, we will load in packages, to get the extra tools we need for this module 
loaded in R! We will load in the tidyverse package. 

```{r}
library(tidyverse)
```


#Load in our data! 

Now it's time to load in our data! (NOTE: this may change if data is not in a 
csv file)

```{r}
water <- read.csv("water_quality.csv", header = TRUE, sep =",")
```

#Viewing the data 

Now that our data is loaded into R, we can explore the data using the view and 
head command. 

```{r}
View(water)
```

```{r}
head(water)
```

*What kind of variables are in our dataset for water quality on the K'avi lands? 

*Are there some variables in particular that you think would be important for 
tribal land managers to focus on to understand how climate change is affecting 
water quality on their lands? 

It may also be helpful for us to understand how big our dataset is. We can 
get this number by using the command "dim".

```{r}
dim(water)
```

*How many data entries are in this dataset? 


## Recap 
You now reviewed ways to set up your R environment, read in data, and explore 
your data! These steps are all important for when we analyze our data later in 
this module. 


--------------------------------------------------------------------------------
#PART 2: Debugging data, and running some basic summary statistics

Tribal land managers are interested in how the temperature and dissolved 
oxygen of the water on their lands have changed over the last several years. 
They are also interested in learning about the mean, median, minimum, and maximum
values of temperature and dissolved oxygen in water they have in their data. 
These values will help them understand how current values compare to the rest of
the values in their data. 

#

```{r}
mean(water$temperature)
```

Ah! Our code didn't work. R gave us an error message that says: "". This means 
we have some missing chunks of data in our dataset that R doesn't know how to 
work with. 

Sometimes when collecting data, it's possible that we don't have all complete 
data sequences for all samples in our data set. While this is very normal, as we can
see, it can make running commands in R a little bit tricky.

These missing data are entered as NA (not availabe) in R automatically.
In this section, we'll go over some easy ways to fix this problem in our "water"
data set by telling R to ignore the NAs. 

```{r}
#JMc We're going to change this to dplyr 
# This will help 
# https://dplyr.tidyverse.org/
# JMc e.g., https://www.youtube.com/watch?v=8SGif63VW6E
na.omit(water)
```

Great! Now let's try to run our command to get the mean for temperature again. 


```{r}
mean(water$temperature)
```

Our code worked! Now you've learned how to handle NAs in a dataset in R. Let's
carry on with our summary statistics.

*Your turn! How would you figure out what the mean amount of dissolved oxygen 
is in the water across all samples? 

```{r}
#Write your code here!

```


#What is the median amount of temperature across all samples? 

```{r}
median(water$temperature)
```


#What is the median amount of dissolved oxygen across all samples? 

```{r}
#Write your code here! 

```

#What is the maximum and minimum temperature in our data?

```{r}
max(water$temperature)
min(water$temperature)
```

#Your turn: figure out the minimum and maximum amount of dissolved oxygen recorded
in our dataset? 

```{r}

```


**QUESTION: Do we want to introduce subsetting in the summary statistics section?
Or do we just want to keep it in the visualizations portion? If so, I would 
have some ideas on how to restructure the rest of this section. 





--------------------------------------------------------------------------------
#PART 3: Visualizing our data! 


