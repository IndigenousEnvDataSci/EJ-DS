---
title: "Mod2_water"
output: html_document
date: "2023-11-14"
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Background for Module 2: Water Quality

Water sustains life on our planet and water is sacred to Native Americans. "Water quality" captures many components of the chemistry, biology, and physics of fresh water. In this module, we will study data about two of these components, water temperature (T) and dissolved oxygen (DO). 

Bull trout are a culturally important, but threatened species of fish native to the U.S. Northwest and the Canadian Rockies. They provide an example of how water quality affects Indigenous culture, because, to thrive, bull trout require water temperatures below 14 degrees C and dissolved oxygen levels above 6.2 mg/L. Such cold clean water conditions are growing scarcer due to climate warming and pollution.

[#JMc note: We need to check these threshold values for T and DO.]

In this module, we will use data about water quality trends to help K'avi Fish and Wildlife managers decide which of two streams would be best for a reintroduction of bull trout on tribal land. The tribe only has funding to bring the bull trout back to one stream. They have narrowed the choice of possible locations for the reintroduction to two streams, where temperature and D.O.have been monitored for about 15 years. Neither site is perfect, but they are both pretty good options. Your job is to analyze the temperature and D.O. data to help the tribe decide which is the best site. 

The upstream source of Stream A is a groundwater spring. Water in this stream is very clean and temperatures are steady because groundwater temperatures tend to match average yearly temperature.

The upstream source of Stream B is an alpine lake that is fed by a glacier. The glacial melt-water is very cold and clean, but the glacier is shrinking as climate warms, so the cold-water input to the lake is growing smaller over time.


**In this module, there are four main coding goals:** 
1. We will review skills you learned in Module 1, such as calculating summary statistics and making scatter plots.

2. We will learn how to rearrange data into a "tidy" format that makes graphing easier
and we will learn how to "debug" code, in other words, we'll learn how to fix common 
problems that we see when using real world data. 

3. We will learn how to make graphs of data over time. These are called 
"time series" graphs.

4. We will explore how water quality data can help communities make decisions 
to protect culturally important species.



--------------------------------------------------------------------------------
#INSTRUCTOR'S VERSION: Learning goals 

1. Students will review the steps to set a working directory and load in data from 
an extrenal data file. 

2. Students will review basic commands in R to explore their data before they 
begin to analyze it. 

3. Students will review how to load in packages. 

4. Students will review basic summary statistic commands in R to pull the mean, 
median, max, and min values for different variables in the dataset. 

5. NEW SKILL: students will learn how to handle common code bugs, such as NAs. 

6. NEW SKILL: students will learn how to subset data in R based on scientifically 
relevant groups. 

7. NEW SKILL/review: Students will review how to make a graph using ggplot. 
Students will learn how to make a new kind of plot in ggplot (line graph),
in addition to the scatterplot and ribbon plot they learned about in Module 1 fish.
This will be framed in understanding how we should present data in a meaningufl 
way to any community, 

--------------------------------------------------------------------------------
#PART 1: Loading in and exploring the data 

Like we did in Module 1, before we being to analyze our data, we need to do a few
steps first.

#Clearing Environment 

Before we start to do anything in R, we should clear our environment. As a reminder,
your environment is where R stores all the objects and data you were working with
since the last time you worked in R. See the code chunk below on how to clear 
your environment. 

```{r}
rm(list = ls())
```


#Setting the Working Directory 

We will now set our working directory. As you may remember, setting our working 
directory tells R where to find the files we want to work with on our computer. 

[JMc comment: We should decide as a class whether we want to set working directories this way, 
or just put the data files in the same directory as this .Rmd file. 
When you knit an R Markdown it looks for the data in that directory.
See this link, too: https://github.com/yihui/knitr/issues/277#issuecomment-6528846
]


```{r}
current_path = rstudioapi::getActiveDocumentContext()$path
setwd(dirname(current_path))
```


#Load in packages 

Next, we will load in packages, to get the extra tools we need for this module 
loaded in R! We will load in the tidyverse package. 

```{r}
library(tidyverse)
```


#Load in our data! 

Now it's time to load in our data! In this scenario, temperature data 
and dissolved oxygen data were collected and stored in two separate files. 
Therefore, we will need to load in both files in order to use them. 

(NOTE: this may change if data is not in a 
csv file)

```{r}
#We will first load in our data for water temperature. 
stream_temp <- read.csv("streams_temperature.csv", header = TRUE, sep =",")
```

```{r}
#Now we will load in our data for dissolved oxygen concentrations.
stream_DO <- read.csv("streams_DissolvedOxygen.csv", header = TRUE, sep =",")
```

#Viewing the data 

Now that our data is loaded into R, we can explore the data using the view and 
head command. 

```{r}
View(stream_temp)
```

```{r}
head(stream_DO)
```

*What do you notice is different between using the command "View" and the command
"head"? Which one do you think is more useful? 

It may also be helpful for us to understand how big our dataset is. We can 
get this number by using the command "dim".

```{r}
dim(stream_temp)
dim(stream_DO)
```

*How many data entries are in this dataset for water temperature? 

*How many data entries are in this dataset for dissolved oxygen? 


RECAP:
You now reviewed ways to set up your R environment, read in data, and explore 
your data! These steps are all important for when we analyze our data later in 
this module. 


--------------------------------------------------------------------------------
#PART 2: Pivoting data, debugging data, and running some basic summary statistics

[CRA: from here up until line 302 are edits I made on 11/28 per the new data]

Tribal land managers are interested in how the temperature and dissolved 
oxygen of the water on their lands have changed over the last several years. 
They are also interested in learning about the mean, median, minimum, and maximum
values of temperature and dissolved oxygen in water they have in their data. 
These values will help them understand how current values compare to the rest of
the values in their data. 


As of now, our data for water temperature for Stream A and B exists in a separate
data frame from the dissolved oxygen concentrations for Stream A and B. For
tribal land managers to truly understand what's going on, they need to analyze
water temperature and dissolved oxygen together. To do this, we need to change 
how our data is set up in each data frame and then merge these data frames together. 

[CRA 11/29 5:30pm: Edit to add text to explain why we want to pivot]
To modify our data we need to do something called "pivoting". In our current 
data for water temperature, we have columns for the year the sample was collected,
the temperature for the samples from Stream A, and the temperature of the samples in 
Stream B. Instead, we want columns for the year, the site where the sample was collected, 
and a column for all the temperatures. 

Another reason we want to "pivot" our data is because tidyverse (the package
we have been using to wrangle, analyze, and then plot our data) prefers our data 
to be in what is called "long form" as opposed to "wide form". Wide form data means 
that there are no repeat values in our data frame. In our case, the repeat data 
we would be looking for is site data, or which Stream was sampled from. This is because 
there are individual columns for each stream. 

"Long form" data means that there are repeated rows for every observation of a value 
made for each stream. In that case,our data frame would look different. A long form version 
of our data means that there would be a column called "site" and a column that contains values for 
temperature and DO for all sites. We would know if the measurement for temperature 
or DO was from stream A or B by looking at the row the data is in, and seeing what 
value is entered in the site column in that row. Long form data makes it easier to
summarize data and look at trends over time, which is why tidyverse prefers it. 

To do this we will use a command from tidyverse called "pivot_longer". See the 
code chunk below for more explanation! 
```{r}
# this first line of code tells R that we want to
# re-save the streams_temp dataset with the changes we make to it with pivot_longer. 
stream_temp <- stream_temp %>%  
#we use the pivot_longer code to tell R which columns we want to change.
  pivot_longer( 
    #cols = tells R which columns we want to modify
    cols = c(StreamA, StreamB), 
    #names_to tells R that we want the names of the columns we 
    #specified in the line above to be entries in a new column we're creating 
    #called "site". 
    names_to = "site", 
    #Based on what "names_to" means, what do you think the next line of code 
    #values_to means? (Hint - searching the internet for the answer is a great
    #way to figure this out, and looking things up is a huge part of coding!)
    values_to = "temperature_C" 
  )
```

To check our work, we can view streams_temp: 
```{r}
View(stream_temp)
```


Great! Our code worked. Now let's do the same for the dissolved oxygen data set.
We want to change it in the same way we changed the temperature data set above. 
[#JMc Note: We could reframe this as an "I do", "We do" exercise, since it's similar to the last code chunk.]

```{r}

stream_DO <- stream_DO %>%
  pivot_longer(
    cols = c(StreamA, StreamB),
    names_to = "site",
    values_to = "dissolved_oxygen"
  )
```

Again, we should check our work to make sure that our data looks the way we want
it to. We want there to be three columns, one for the year the sample was collected,
one for the site name, and one for the dissovled oxygen values (mg/L). 

```{r}
View(stream_DO)
```

Good work! This data frame looks the way we want it to now as well. 

Next, we need to merge these two data frames together into one, so we can analyze 
trends in temperature and dissolved oxygen at the same time for both streams. 


To do this, we will use a command in tidyverse called "left_join". 
Left join means we want to put one data frame next to the the other. In other words, 
we want to match up the rows in the data frame, so it becomes wider, not longer. This is 
because we want to preserve the columns from the two data frames we are combining. 
```{r}
#Here, we are using left_join to put the streams_temp data frame next to the streams_DO
#data frame.
streams <- left_join(stream_temp,stream_DO)

```


Great! Now let's check to make sure that we successfully merged our two data frames.
```{r}
View(streams)
```


Great job data wrangling! We can now continue to analyze our data. 


#

[#JMc note to CRA @ 11/28 8pm: I think code below here needs updating.]
```{r}
mean(streams$temperature)
```

Ah! Our code didn't work. R gave us an error message that says: "". This means 
we have some missing chunks of data in our data set that R doesn't know how to 
work with. 

Sometimes when collecting data, it's possible that we don't have all complete 
data sequences for all samples in our data set. While this is very normal, as we can
see, it can make running commands in R a little bit tricky.

These missing data are entered as NA (not available) in R automatically.
In this section, we'll go over some easy ways to fix this problem in our "water"
data set by telling R to ignore the NAs. 

```{r}
#JMc We're going to change this to dplyr 
# This will help 
# https://dplyr.tidyverse.org/
# JMc e.g., https://www.youtube.com/watch?v=8SGif63VW6E
na.omit(streams)
```

Great! Now let's try to run our command to get the mean for temperature again. 


```{r}
mean(streams$temperature)
```

Our code worked! Now you've learned how to handle NAs in a dataset in R. Let's
carry on with our summary statistics.

*Your turn! How would you figure out what the mean amount of dissolved oxygen 
is in the water across all samples? 

```{r}
#Write your code here!

```


#What is the median amount of temperature across all samples? 

```{r}
median(streams$temperature)
```


#What is the median amount of dissolved oxygen across all samples? 

```{r}
#Write your code here! 

```

#What is the maximum and minimum temperature in our data?

```{r}
max(streams$temperature)
min(streams$temperature)
```

#Your turn: figure out the minimum and maximum amount of dissolved oxygen recorded
in our dataset? 

```{r}

```
