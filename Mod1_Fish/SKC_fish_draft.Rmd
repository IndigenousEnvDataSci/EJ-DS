---
title: "SKC_fish_1"
output: html_document
date: "2023-10-24"
---

# DRAFT: Background of the vignette for fish

Members of the K’avi have fished the waters on their land for many years
to provide food for their community. To manage these waters, K'avi tribal fishery managers have been monitoring fish growth rates across the local water bodies in their community. 


However, many members of the community have begun to experience 
health problems associated with heavy metal poisoning. 
Historically, a factory used to be located upstream of the riverways fished by 
the K’avi, and waste from this factory was dumped into the nearby waters. 
Tribal fishery managers are now concerned that members of the community 
are being exposed to heavy metals through the fish that have been caught in these
waters. As a result, they now want to start recording the concentrations of methyl
mercury in the belly fat of fish in the area.
Their hope is to gain insight as to if the symptoms their community 
members are facing are connected to the fish being sourced from their waters. 


Once they collect these data, the tribal fishery managers will need to present 
their findings to members of the community so they can better understand the
public health crisis at hand. 


In this module, there are three main goals: 
1. Explore data related to fish growth and heavy metal concentrations.
2. Explore K'avi community health data.
3. Connect these datasets and produce a graph that could be used 
to communicate the fishery managers' findings to their community. 

--------------------------------------------------------------------------------
# WORKSHOP: Learning goals (More for us as a team, rather than for SKC students)

1. Students become more comfortable opening R and loading in data from an 
external data file. 
  - Considerations: do we want this file to be a csv? 
  
2. Students gain exposure to basic commands to explore their data before 
they begin to analyze it. 
  - Considerations: are these coded in baseR, do we want students to use tidyverse?
  
3. Students gain experience loading in packages (tidyverse and ggplot). 

4. Students gain exposure to working with different data types(numeric, characters)

5. Students gain exposure to basic summary statistic arguments in R to pull the 
mean, median, max, and min values for different variables in the dataset. 

6. Students become equipped with how to make a graph in R (tidyverse, ggplot) 
using variables pulled from a larger dataset. Can open a discussion point: 
how do we present data in a way that can help us understand the problem at hand?
(i.e. in this case, it may be plotting mercury concentrations found in fish 
along different sites, and showing it next to a graph of mercury found in people
across different sites)


--------------------------------------------------------------------------------
# PART 1: Loading in and exploring the data

Before we begin to analyze the data, we first need to upload our raw data into R. 
Once we do that, we can then explore...

**QUESTION: do we want students to jump in using tidyverse right away?

## Clearing Environment

The first thing we do anytime we start working in R is cleaning our environment. Your environment is where R stores all of the objects it is working with since the last time you cleared your environment. We clear the environment each time we open R so that there isn't anything still open from the list time you were using R that will mess up what we are trying to do this session. You can clear your environment with the following code or by clicking the broom icon that can normally be found on the top right section of RStudio. 

```{r}
rm(list = ls())
```


## Setting the Working Directory

In the following code we will tell the computer where we want it to look for 
  files on our computer. This is called a working directory. We will discuss this
  more in depth later. --- Hannah: or will we? Did we do this in module 0? ---
```{r set wd}
current_path = rstudioapi::getActiveDocumentContext()$path
setwd(dirname(current_path))
```



## Load in packages 

Think of packages as tools for you to use in R that aren't automatically part of
R when you first installed it. The package below allows you to do way more things
in R, and for coding to be much easier! 

 --- Hannah: ggplot2 and dplyr are both a part of tidyverse so installing and loading tidyverse will install and load the others too. ---
 
```{r load packages}
if(!require("tidyverse")) install.packages("tidyverse") #how you install a package (only need to do this once on your computer)
library(tidyverse) #how to load in a package that has already been installed
```


## Now we will load in the dataset for the physical fish data

```{r fish}
#fish <- read.csv("fish_1998.csv", header = TRUE, sep = ',')
```
#skip this part for now, this is all for if/when we change the .RData file into a csv!
Let's break down the different parts of what just happened:
1) We told R to read the data (a .csv file) using the command read.csv()
2) Within the (""), we identify the data file from our working directory that we want to load into R
3) header = TRUE just tells R that the first row of data is the column names. The alternative is header = FALSE
4) sep is short for the word "separate", and it tells R that each column in the csv is separated by a comma ','
3) "fish" is the name we are giving that file in R, and is how we will refer to this data going forward.
4) <- is like = in a math equation, it tells R that "fish" is the same as the data "fish_1998.csv"

```{r fish RData}
load("fish_1998.RData")
fish <- fish_1998
```

## Viewing the data

Now that we have brought the data into R we can look at the data with the following command. 
```{r view data pt. 1}
View(fish) 
```

## Different way to view the data

If we don't want to look at all of the data and instead just want to see what is going on in the first couple rows we can use the following code. 
``` {r view data pt. 2}
head(fish) #just shows the column names and the first few rows of the data
```
* Now that you have taken a look at it in R, what is data?

* What data do we have? What sort of questions can the tribal fishery managers ask with this data?

## Exploring the dimensions of the data

To answer these questions, it would be helpful to know how many fish we actually have data for!
Fortunately, we can very quickly find that out with the following code.
```{r explore data dimensions}
dim(fish) #shows the dimensions of the dataset, which will be important later on
```

* How many fish do we have data for?


# PART 2: Running some basic statistics! 

According to the EPA, the maximum safe level of mercury to be consumed is around
0.1 mg/kg/day. Tribal fishery managers are interested in whether the mercury levels in 
local fish belly fat exceeds this threshold. They are also interested in if the 
amount of mercury in fish is connected to fish size. 

Below, we will analyze data points from the "fish" data set to try and answer 
these questions. 


## What is the mean amount of mercury found in local fish? 

```{r mean amount of mercury}
mean(fish$mercury)
#you can see that $ is how you tell R what variable/column you want to work with
```


## What is the median amount of mercury found in fish?

```{r median amount of mercury}
median(fish$mercury)
```

## How would we interpret these median and mean values? Should the K'avi community be concerned?



## Now figure out what the maximum and minimum amount of mercury was found in fish:

``` {r max and minimum amount of mercury}


```

## How would we interpret these maximum and minimum values? Are they as important as the average?

## There is a faster way to get all of these basic statistics at once:
``` {r summary stats}
summary(fish$mercury)
```

# PART 3: Working with ggplot to generate a graph of mercury concentrations in 
fish belly fat against some variable of interest (fish length, boxplots for 
fish age). 

# First we want to visualize the distributions of the fish by length and 
by the amount of mercury that they have. We can do this by creating graphs
(which we'll talk about in a later module)

## Introducing ggplot and the syntax? Give a commented out example maybe for 
Georgia to walk through (ggplot(data, aes(x,y) etc.)) ? 

#Don't worry about the code below (unless you would like to explore it), just focus on the 
graph that it creates and interpreting its results. 

```{r ggplot, Ribbon Plot, length}
# For this plot, we want to see the distributions of lengths across the fish and how many of them are above 50 cm. 
 ggplot(fish_1998, aes(y=length, x= "fish"))+
# x="fish" indicates that the x axis doesn't have a variable and is titled fish. This allows us to look at the variation in lengths of fish independent of another variable.
  geom_hline(yintercept = 50, color= "red")+
  geom_jitter(width = 0.1)
# the jitter plot is a variation on the scatterplot, but it separates the data so that we can distinguish how many points are above 50 cm. To see the difference, try geom_point () and then geom_jitter ()!
```
What does this tell us about the lengths of the fish in the lake?


```{r ggplot, Ribbon Plot, mercury}
 ggplot (fish_1998, aes(x= 'fish', y= mercury))+
  geom_jitter(width = 0.1)+
  geom_hline(yintercept = 4, color= "red")

```
#What does this distribution tell us about the mercury levels in the fish?


#Now that we have seen the distributions of the lengths of the fish and the mercury levels in the lake, we can look at the realtionship between them. Again, don't worry about the code below, just think about the information that we can take from it. 

```{r ggplot, Scatter Plot}
#ggplot is the function that we are using to create a plot. aes() is used to tell ggplot #what we want to see on each axis, in this case x= length and y= mercury.
  p1<- ggplot(fish_1998, aes(x = length, y = mercury)) +
#Since ggplot is just a function to create plots, we need to further specify
#what kind of plot it should create. We can do this by using the geom_point
#function. Because we are making a scatter plot, we use the function geom_point().
#We can also add a few more parameters to the graph, such as changing the color
#of the points (color = 'blue), or the size of them (size [2]).
  geom_point(color = 'blue', size = 2) +
  ggtitle('mercury levels in 1998') +
#We can also add shapes to the plot. Here we added a dashed line to show where 
#the EPA's guideline for unsafe levels of mercury in fish would fall. To create 
#this we used the geom_hline function which simply creates a horizontal line at
#a y-intercept that you set. We can also adjust the color and appearance of the 
#line with linetype and color.
  geom_hline(yintercept = 4.5, linetype= "dashed", color = 'red')
p1
```

#What does this tell us about the relationship between fish length and mercury levels? Are there certain lengths of fish that have a higher amount of mercury? 


--------------------------------------------------------------------------------

# DAY 2: 

We will now analyze data collected from the same monitoring sites in the K'avi 
community from 25 years later (2023). In light of data collected in 1998, efforts were 
made to clean up the heavy metals present in the water that were becoming concentrated
in the local fish populations. 

--- Hannah: Could we maybe change this to say something along the lines of: "In light of the data collected in 1998 and the presentations that the data scientists made to the community... I just feel like we should in some way emphazise the role of data science in this change ---

Our goal today is to see whether the efforts made by tribal fishery managers were 
effective in reducing the amount of mercury present in the fish. 

# PART 1: Loading in and exploring the data

Like we did on Day 1 of the fish module, we first need to load in our datasets!


## First, we check and set our working directory. First we will use the getwd()
command to figure out which working directory we are currently in. Then we will 
use "setwd()" to change our working directory to the directory where our data lives.
The easiest way to think of a directory is as a location on your computer where 
data and other files are located. Each of these directories can be accessed with 
their own unique file path, which is basically a list of different locations on 
your computer that becomes more specific as it continues! 

--- Hannah: Are we having both of these in the same document? If so then we do not need to set the working directory twice. If we are splitting them then I will change this to match the above ---

```{r set wd2}
# getwd()
# setwd()
# list.files()
```


## Load in packages 

We will be using the same packages as we used on Day 1. Remember to load packages, 
we used the command library(), with the name of the package in the parentheses. 

--- Hannah: See comment aboev ---

```{r load packages2}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(patchwork)
```
#Troubleshoot: If that didn't work, it might be because you don't already have 
#these packages installed. To install them, copy this code: install.packages("tidyverse") 
#above the line library(tidyverse), and see if that works. 


## Now we will load in the dataset for the physical fish data

```{r fish2}
#fish <- read.csv("fish_2023.csv", header = TRUE, sep = ',')
load("fish_2023.RData")
fish_2 <- fish_2023
```

Let's break down the different parts of what just happened:
1) We told R to read the data (a .csv file) using the command read.csv()
2) Within the (""), we identify the data file from our working directory that we want to load into R
3) header = TRUE just tells R that the first row of data is the column names. The alternative is header = FALSE
4) sep is short for the word "separate", and it tells R that each column in the csv is separated by a comma ','
3) "fish" is the name we are giving that file in R, and is how we will refer to this data going forward.
4) <- is like = in a math equation, it tells R that "fish" is the same as the data "fish_1998.csv"

## Viewing the data
```{View data pt. 1 - take 2}
View(fish_2) 
```

## Different way to view the data
``` {View data pt. 2 - take 2}
head(fish_2) #just shows the column names and the first few rows of the data
```

What data do we have? What sort of questions can we ask with this data?

## Exploring the dimensions of the data

```{r explore data dimensions 2}
dim(fish_2) #shows the dimensions of the dataset, which will be important later on
```


# PART 2: Running some basic statistics! 

According to the EPA, the maximum safe level of mercury to be consumed is around
0.1 mg/kg/day. Tribal fishery managers are interested in how mercury levels in 
fish belly fat have changed since 1998 to 2023, now that the rivers have been 
cleaned

Below, we will analyze data points from the "fish_2" data set to try and answer 
these questions. 


## What is the mean amount of mercury found in fish across all sites in 2023? 

```{r mean amount of mercury 2}
mean(fish_2$mercury_2023)
#you can see that $ is how you tell R what variable/column you want to work with
```


## What is the median amount of mercury found in fish in 2023?

```{r median amount of mercury 2}
median(fish_2$mercury_2023)
```

## How would we interpret these median and mean values? How do these values compare from 
the values we generated last class using the "fish" data from 1998? 



## Now figure out what the maximum and minimum amount of mercury was found in fish
in 2023:
``` {r max and minimum amount of mercury 2}


```
 
 
# PART 3: In order to best visualize how mercury levels in fish have been affected
by the waterway clean up, tribal fishery managers believe that making a graph 
will be the most effective. 

We'll practice using ggplot again to visualize fish 
data from the fish_2023 dataset, and compare our results to those we generated 
with the fish_1998 dataset. 

## Recall from last class the steps to make a plot with ggplot:
```{r ggplot, Scatter Plot 2}
#Call "ggplot" followed by the "aes() argument. Which data would 
  #go on the x and y axis? 
p2<- ggplot(fish_2023, aes(x = length, y = mercury)) +
#Now it's time to specify which plot we want ggplot to make. A scatterplot
#would be good to visualize our data, so we will call "geom_point()". In the 
#parentheses, we can specify extra details about how we want the graph to appear.
#Here, we will set the color to green, and the size of the points to 2. 
  geom_point(color = 'green', size = 2) +
  ggtitle('mercury levels in 2023')+
#To truly understand if efforts to clean up the waterways made a difference in 
#mercury concentrations in the fish, we will again place a dashed line on the 
#graph where the EPA deems the unsafe level of mercury in fish would be. We will
#do this by calling geom_hline, then setting the y-intercept of where we want the
#line to be placed, set the "linetype" and set the "color" of the line. 
geom_hline(yintercept = 4.5, linetype= "dashed", color = 'red')
p1+p2
```

## INTERPRETATION: Based on the distribution of data in our plot from the fish_2023
dataset compared to how our plot looked with the fish_1998 dataset, were the clean-up
efforts successful? If so, how can you tell? 