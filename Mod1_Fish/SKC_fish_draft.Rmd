---
title: "SKC_fish_1"
output: html_document
date: "2023-10-24"
---

# DRAFT: Background of the vignette for fish

Members of the K’avi have fished the waters on their land for many years
to provide food for their community. To manage these waters, K'avi tribal fishery managers have been monitoring fish growth rates across the local water bodies in their community. 


However, many members of the community have begun to experience 
health problems associated with heavy metal poisoning. 
Historically, a factory used to be located upstream of the riverways fished by 
the K’avi, and waste from this factory was dumped into the nearby waters. 
Tribal fishery managers are now concerned that members of the community 
are being exposed to heavy metals through the fish that have been caught in these
waters. As a result, they now want to start recording the concentrations of methyl
mercury in the belly fat of fish in the area.
Their hope is to gain insight as to if the symptoms their community 
members are facing are connected to the fish being sourced from their waters. 


Once they collect these data, the tribal fishery managers will need to present 
their findings to members of the community so they can better understand the
public health crisis at hand. 


In this module, there are three main goals: 
1. Explore data related to fish growth and heavy metal concentrations.
2. Explore K'avi community health data.
3. Connect these datasets and produce a graph that could be used 
to communicate the fishery managers' findings to their community. 

--------------------------------------------------------------------------------
# WORKSHOP: Learning goals (More for us as a team, rather than for SKC students)

1. Students become more comfortable opening R and loading in data from an 
external data file. 
  - Considerations: do we want this file to be a csv? 
  
2. Students gain exposure to basic commands to explore their data before 
they begin to analyze it. 
  - Considerations: are these coded in baseR, do we want students to use tidyverse?
  
3. Students gain experience loading in packages (tidyverse and ggplot). 

4. Students gain exposure to working with different data types(numeric, characters)

5. Students gain exposure to basic summary statistic arguments in R to pull the 
mean, median, max, and min values for different variables in the dataset. 

6. Students become equipped with how to make a graph in R (tidyverse, ggplot) 
using variables pulled from a larger dataset. Can open a discussion point: 
how do we present data in a way that can help us understand the problem at hand?
(i.e. in this case, it may be plotting mercury concentrations found in fish 
along different sites, and showing it next to a graph of mercury found in people
across different sites)


--------------------------------------------------------------------------------
# PART 1: Loading in and exploring the data

Before we begin to analyze the data, we first need to upload our raw data into R. 
Once we do that, we can then explore...

**QUESTION: do we want students to jump in using tidyverse right away?

## Clearing Environment

The first thing we do anytime we start working in R is cleaning our environment. Your environment is where R stores all of the objects it is working with since the last time you cleared your environment. We clear the environment each time we open R so that there isn't anything still open from the list time you were using R that will mess up what we are trying to do this session. You can clear your environment with the following code or by clicking the broom icon that can normally be found on the top right section of RStudio. 

```{r}
rm(list = ls())
```


## Setting the Working Directory

In the following code we will tell the computer where we want it to look for 
  files on our computer. This is called a working directory. We will discuss this
  more in depth later. --- Hannah: or will we? Did we do this in module 0? ---
```{r set wd}
current_path = rstudioapi::getActiveDocumentContext()$path
setwd(dirname(current_path))
```



## Load in packages 

Think of packages as tools for you to use in R that aren't automatically part of
R when you first installed it. The package below allows you to do way more things
in R, and for coding to be much easier! 

 --- Hannah: ggplot2 and dplyr are both a part of tidyverse so installing and loading tidyverse will install and load the others too. ---
 
```{r load packages}
if(!require("tidyverse")) install.packages("tidyverse") #how you install a package (only need to do this once on your computer)
library(tidyverse) #how to load in a package that has already been installed
```


## Now we will load in the dataset for the physical fish data

```{r fish}
#fish <- read.csv("fish_1998.csv", header = TRUE, sep = ',')
```
#skip this part for now, this is all for if/when we change the .RData file into a csv!
Let's break down the different parts of what just happened:
1) We told R to read the data (a .csv file) using the command read.csv()
2) Within the (""), we identify the data file from our working directory that we want to load into R
3) header = TRUE just tells R that the first row of data is the column names. The alternative is header = FALSE
4) sep is short for the word "separate", and it tells R that each column in the csv is separated by a comma ','
3) "fish" is the name we are giving that file in R, and is how we will refer to this data going forward.
4) <- is like = in a math equation, it tells R that "fish" is the same as the data "fish_1998.csv"

```{r fish RData}
load("fish_1998.RData")
fish <- fish_1998
```

## Viewing the data

Now that we have brought the data into R we can look at the data with the following command. 
```{r view data pt. 1}
View(fish) 
```

## Different way to view the data

If we don't want to look at all of the data and instead just want to see what is going on in the first couple rows we can use the following code. 
``` {r view data pt. 2}
head(fish) #just shows the column names and the first few rows of the data
```
* Now that you have taken a look at it in R, what is data?

* What data do we have? What sort of questions can the tribal fishery managers ask with this data?

## Exploring the dimensions of the data

To answer these questions, it would be helpful to know how many fish we actually have data for!
Fortunately, we can very quickly find that out with the following code.
```{r explore data dimensions}
dim(fish) #shows the dimensions of the dataset, which will be important later on
```

* How many fish do we have data for?

## Recap
You now know the basic ways to look at and understand your data in R, which will
come in handy any time you use R in the future! We now know what sort of questions
we can ask with this data, but how can we use R to answer those questions?

# PART 2: Running some basic statistics! 

According to the EPA, the maximum safe level of mercury to be consumed is around
0.1 mg/kg/day. Tribal fishery managers are interested in whether the mercury levels in 
local fish belly fat exceeds this amount. They are also interested in if the 
amount of mercury in fish is connected to fish size. 

Below, we will analyze data points from the "fish" data set to try and answer 
these questions. 


## What is the mean amount of mercury found in local fish? 

```{r mean amount of mercury}
mean(fish$mercury)
#you can see that $ is how you tell R what variable/column you want to work with
```
What does the mean tell you? Why would this be useful for fishery managers?

--Evan: Not sure if I want them to interpret these values and also explain what mean, median etc. are, or if I should provide a brief explanation of what they each are?--

## What is the median amount of mercury found in fish?

```{r median amount of mercury}
median(fish$mercury) #for students, can just be given median() and then they have to fill in fish$mercury
```
What does the median tell you? How is it different from the mean? 

* How would we interpret these median and mean values? Should the K'avi community be concerned?



## Now figure out what the maximum and minimum amount of mercury was found in fish:

``` {r max and minimum amount of mercury}


```

* How would we interpret these maximum and minimum values? Are they as important as the average?

## There is a faster way to get all of these basic statistics at once:
``` {r summary stats}
summary(fish$mercury)
#1st Qu. and 3rd Qu. refer to the 1st and 3rd "Quartiles". Don't worry too much about quartiles right now, but if you're curious, they represent a quarter of the data. They basically tell you that 25% of the data is between that value, the Median, and either the Min. (1st Qu.) or Max. (3rd Qu.).
```

* Looking at all of these values, are there unsafe levels of mercury in local fish? 
  If so, is it in most fish, or only some? 

* Would you recommend cleaning up the river based on these values? 

Cleaning up the waterway may take some time, is it possible for members of the 
K'avi community to safely continue fishing these waters in the meantime? Are fish 
of certain sizes more safe to eat than others?

## Recap: How could we communicate these values? 
You now know how to get basic statistics in R, and that has already given a lot 
of helpful information for tribal fishery managers! However, summary stats can't 
answer every question, and as a list of numbers they would be very difficult to 
communicate to the K'avi community. It would be much more helpful to visualize the data!

# PART 3: Working with ggplot to generate a graph of mercury concentrations in 
fish belly fat against some variable of interest (fish length, boxplots for 
fish age). 

# First we want to visualize the distributions of the fish by length and 
by the amount of mercury that they have. We can do this by creating graphs
(which we'll talk about in a later module)

## Introducing ggplot and the syntax? Give a commented out example maybe for 
Georgia to walk through (ggplot(data, aes(x,y) etc.)) ? 

#Don't worry about the code below (unless you would like to explore it), just focus on the 
graph that it creates and interpreting its results. 

```{r ggplot, Ribbon Plot, length}
# For this plot, we want to see the distributions of lengths across the fish and how many of them are above 50 cm. 
 ggplot(fish_1998, aes(y=length, x= "fish"))+
# x="fish" indicates that the x axis doesn't have a variable and is titled fish. This allows us to look at the variation in lengths of fish independent of another variable.
  geom_hline(yintercept = 50, color= "red")+
  geom_jitter(width = 0.1)
# the jitter plot is a variation on the scatterplot, but it separates the data so that we can distinguish how many points are above 50 cm. To see the difference, try geom_point () and then geom_jitter ()!
```
What does this tell us about the lengths of the fish in the lake?


```{r ggplot, Ribbon Plot, mercury}
 ggplot (fish_1998, aes(x= 'fish', y= mercury))+
  geom_jitter(width = 0.1)+
  geom_hline(yintercept = 4, color= "red")

```
#What does this distribution tell us about the mercury levels in the fish?


#Now that we have seen the distributions of the lengths of the fish and the mercury levels in the lake, we can look at the realtionship between them. Again, don't worry about the code below, just think about the information that we can take from it. 

```{r ggplot, Scatter Plot}
#ggplot is the function that we are using to create a plot. aes() is used to tell ggplot #what we want to see on each axis, in this case x= length and y= mercury.
  p1<- ggplot(fish_1998, aes(x = length, y = mercury)) +
#Since ggplot is just a function to create plots, we need to further specify
#what kind of plot it should create. We can do this by using the geom_point
#function. Because we are making a scatter plot, we use the function geom_point().
#We can also add a few more parameters to the graph, such as changing the color
#of the points (color = 'blue), or the size of them (size [2]).
  geom_point(color = 'blue', size = 2) +
  ggtitle('mercury levels in 1998') +
#We can also add shapes to the plot. Here we added a dashed line to show where 
#the EPA's guideline for unsafe levels of mercury in fish would fall. To create 
#this we used the geom_hline function which simply creates a horizontal line at
#a y-intercept that you set. We can also adjust the color and appearance of the 
#line with linetype and color.
  geom_hline(yintercept = 4.5, linetype= "dashed", color = 'red')
p1
```

#What does this tell us about the relationship between fish length and mercury levels? Are there certain lengths of fish that have a higher amount of mercury? 


--------------------------------------------------------------------------------

# DAY 2: 

We will now analyze data collected from the same monitoring sites in the K'avi 
community from 25 years later (2023). In light of data collected in 1998 and the
presentations tribal fishery managers made to communicate their findings to the 
community,efforts were made to clean up the heavy metals present in the water 
that were becoming concentrated in the local fish populations. 

--- Hannah: Could we maybe change this to say something along the lines of: "In light of the data collected in 1998 and the presentations that the data scientists made to the community... I just feel like we should in some way emphasize the role of data science in this change ---

---Catherine: I agree! See changes made above!---


Our goal today is to see whether the efforts made by tribal fishery managers were 
effective in reducing the amount of mercury present in the fish. We will do this
by comparing our findings from the 1998 dataset to our current findings in the 2023
dataset. 

# PART 1: Loading in and exploring the data

Like we did on Day 1 of the fish module, we first need to load in our datasets!

Before we begin, we check and set our working directory. First we will use the getwd()
command to figure out which working directory we are currently in. Then we will 
use "setwd()" to change our working directory to the directory where our data lives.
The easiest way to think of a directory is as a location on your computer where 
data and other files are located. Each of these directories can be accessed with 
their own unique file path, which is basically a list of different locations on 
your computer that becomes more specific as it continues! 

--- Hannah: Are we having both of these in the same document? If so then we do not need to set the working directory twice. If we are splitting them then I will change this to match the above ---

---Catherine: That's a good point, and based on what we discussed last class I 
think that both days' assignments will be in the same document so students can 
generate both plots easily and place them side by side?---

```{r set wd2}
# getwd()
# setwd()
# list.files()
```


## Load in packages 

We will be using the same packages as we used on Day 1. Remember to load packages, 
we used the command library(), with the name of the package in the parentheses. 

--- Hannah: See comment above ---

```{r load packages2}
library(tidyverse)

#We will need to use a new package today that we haven't installed before called 
#patchwork.
if(!require("patchwork")) install.packages("patchwork") 
library(patchwork)
```



## Now we will load in the dataset for the physical fish data

```{r fish2}
#fish <- read.csv("fish_2023.csv", header = TRUE, sep = ',')
load("fish_2023.RData")
fish_2 <- fish_2023
```


## Now that we have loaded our data, we can begin to explore it to see what it 
contains. 

```{View data pt. 1 - take 2}
View(fish_2) 
```

## Recall from last class that there is another way to view only a small part 
of our dataframe, using the arugement "head()". 

*What would go in the parentheses of head() in order to get the output you want?
``` {View data pt. 2 - take 2}
head() #Fill in the parentheses 
```

*What are the variables that this data set contains?

## It can also be helpful to explore the dimensions (size) of our dataset, so 
we know how big our sample size is. To do this, we will use the function "dim()".

```{r explore data dimensions 2}
dim() #Fill in the parentheses with the name of the dataframe
```


# PART 2: Running some basic statistics! 

According to the EPA, the maximum safe level of mercury to be consumed is around
0.1 mg/kg/day. Tribal fishery managers are interested in how mercury levels in 
fish belly fat have changed since 1998 to 2023, now that the rivers have been 
cleaned

Below, we will analyze data points from the "fish_2" data set to try and answer 
these questions. 


## What is the mean amount of mercury found in fish in 2023? 

```{r mean amount of mercury 2}
mean(fish_2$mercury_2023)

```

## More practice with mean! How would you figure out what the mean length of fish
sampled was in 2023? 

```{r mean length of fish- student practice}

```


## What is the median amount of mercury found in fish in 2023?

```{r median amount of mercury 2}
median(fish_2$mercury_2023)
```

## More practice with median! How would you figure out what the median length of fish
##sampled was in 2023? 

```{r median length of fish- student practice}

```


## How would we interpret these median and mean values of methyl mercury in fish?
## How do these values compare to the values we drew from the 1998 dataset?



## Now figure out what the maximum and minimum amount of mercury was found in fish
##in 2023: your turn to fill in the parentheses!
``` {r max and minimum amount of mercury 2}
max()
min()
```
 
 
# PART 3: In order to best visualize how mercury levels in fish have been affected
by the waterway clean up, tribal fishery managers believe that making a graph 
will be the most effective. 

We'll practice using ggplot again to visualize fish 
data from the fish_2023 dataset, and compare our results to those we generated 
with the fish_1998 dataset. 

## Recall from last class the steps to make a plot with ggplot:
```{r ggplot, Scatter Plot 2}
#Call "ggplot" followed by the "aes() argument. Which data would 
  #go on the x and y axis? 
p2<- ggplot(fish_2023, aes(x = length, y = mercury)) +
#Now it's time to specify which plot we want ggplot to make. A scatterplot
#would be good to visualize our data, so we will call "geom_point()". In the 
#parentheses, we can specify extra details about how we want the graph to appear.
#Here, we will set the color to green, and the size of the points to 2. 
  geom_point(color = 'green', size = 2) +
  ggtitle('mercury levels in 2023')+
#To truly understand if efforts to clean up the waterways made a difference in 
#mercury concentrations in the fish, we will again place a dashed line on the 
#graph where the EPA deems the unsafe level of mercury in fish would be. We will
#do this by calling geom_hline, then setting the y-intercept of where we want the
#line to be placed, set the "linetype" and set the "color" of the line. 
geom_hline(yintercept = 4.5, linetype= "dashed", color = 'red')
```

## Tribal fishery managers believe that the best way to see if efforts to clean 
## the waterways were successful would be to put our plot from 1998 next to 
## our plot from 2023.

```{r putting plots side by side}
p1 + p2 #plot from 1998 next to plot from 2023 
```

## INTERPRETATION: Based on the distribution of data in our plot from the fish_2023
dataset compared to how our plot looked with the fish_1998 dataset, were the clean-up
efforts successful? If so, how can you tell? 