---
title: "SKC_fish_1"
output: html_document
date: "2023-10-24"
---

# DRAFT: Background of the vignette for fish

Members of the K’avi have fished the waters on their land for many years
to provide food for their community. To manage these waters, K'avi tribal fishery managers have been monitoring fish growth rates across the local water bodies in their community. 


However, many members of the community have begun to experience 
health problems associated with heavy metal poisoning. 
Historically, a factory used to be located upstream of the riverways fished by 
the K’avi, and waste from this factory was dumped into the nearby waters. 
Tribal fishery managers are now concerned that members of the community 
are being exposed to heavy metals through the fish that have been caught in these
waters. As a result, they now want to start recording the concentrations of methyl
mercury and selenium in the belly fat of fish across different sites in the area.
Their hope is to gain insight as to if the symptoms their community 
members are facing are connected to the fish being sourced from their waters. 


Once they collect these data, the tribal fishery managers will need to present 
their findings to members of the community so they can better understand the
public health crisis at hand. 


In this module, there are three main goals: 
1. Explore data related to fish growth and heavy metal concentrations.
2. Explore K'avi community health data.
3. Connect these datasets and produce a graph that could be used 
to communicate the fishery managers' findings to their community. 

--------------------------------------------------------------------------------
# WORKSHOP: Learning goals (More for us as a team, rather than for SKC students)

1. Students become more comfortable opening R and loading in data from an 
external data file. 
  - Considerations: do we want this file to be a csv? 
  
2. Students gain exposure to basic commands to explore their data before 
they begin to analyze it. 
  - Considerations: are these coded in baseR, do we want students to use tidyverse?
  
3. Students gain experience loading in packages (tidyverse and ggplot). 

4. Students gain exposure to working with different data types(numeric, characters)

5. Students gain exposure to basic summary statistic arguments in R to pull the 
mean, median, max, and min values for different variables in the dataset. 

6. Students become equipped with how to make a graph in R (tidyverse, ggplot) 
using variables pulled from a larger dataset. Can open a discussion point: 
how do we present data in a way that can help us understand the problem at hand?
(i.e. in this case, it may be plotting mercury concentrations found in fish 
along different sites, and showing it next to a graph of mercury found in people
across different sites)


--------------------------------------------------------------------------------
# PART 1: Loading in and exploring the data

Before we begin to analyze the data, we first need to upload our raw data into R. 
Once we do that, we can then explore...

**QUESTION: do we want students to jump in using tidyverse right away?

## First, we check and set our working directory(is this something we want students
to do?)

```{r set wd}
getwd()
list.files()
```


## Load in packages 

Think of packages as tools for you to use in R that aren't automatically part of
R when you first installed it. The packages below allow you to do way more things
in R, and for coding to be much easier! These packages actually work in harmony 
with one another, and are part of the "tidyverse".

```{r load packages}
library(tidyverse)
library(dplyr)
library(ggplot2)
```
#Troubleshoot: If that didn't work, it might be because you don't already have 
#these packages installed. To install them, copy this code: install.packages("tidyverse") 
#above the line library(tidyverse), and see if that works. 


## Now we will load in the dataset for the physical fish data

```{r fish}
fish <- read.csv("fish_1998.csv", header = TRUE, sep = ',')
```

Let's break down the different parts of what just happened:
1) We told R to read the data (a .csv file) using the command read.csv()
2) Within the (""), we identify the data file from our working directory that we want to load into R
3) header = TRUE just tells R that the first row of data is the column names. The alternative is header = FALSE
4) sep is short for the word "separate", and it tells R that each column in the csv is separated by a comma ','
3) "fish" is the name we are giving that file in R, and is how we will refer to this data going forward.
4) <- is like = in a math equation, it tells R that "fish" is the same as the data "fish_1998.csv"

## Viewing the data
```{View data pt. 1}
View(fish) 
```

## Different way to view the data
``` {View data pt. 2}
head(fish) #just shows the column names and the first few rows of the data
```

What data do we have? What sort of questions can we ask with this data?

## Exploring the dimensions of the data

```{r explore data dimensions}
dim(data) #shows the dimensions of the dataset, which will be important later on
```


# PART 2: Running some basic statistics! 

According to the EPA, the maximum safe level of mercury to be consumed is around
0.1 mg/kg/day. Tribal fishery managers are interested in how mercury levels in 
fish belly fat vary across different monitoring sites. They are 
also interested in if the amount of mercury in fish is connected to fish size. 

Below, we will analyze data points from the "fish" data set to try and answer 
these questions. 


## What is the mean amount of mercury found in fish across all sites? Across 
different sites? 

```{r mean amount of mercury}
mean(fish$mercury_1998)
#you can see that $ is how you tell R what variable/column you want to work with
```


## What is the median amount of mercury found in fish?

```{r median amount of mercury}
median(fish$mercury_1998)
```

#How would we interpret these median and mean values? Should the Kavi community be concerned?



## Now figure out what the maximum and minimum amount of mercury was found in fish:

``` {r max and minimum amount of mercury}


```
 

# PART 3: Working with ggplot to generate a graph of mercury concentrations in 
fish belly fat against some variable of interest (fish length, boxplots for 
fish age). 


## Introducing ggplot and the syntax? Give a commented out example maybe for 
Georgia to walk through (ggplot(data, aes(x,y) etc.)) ? 

```{r ggplot, Scatter Plot}

#Again, setting the data frame, this time we are creating a plot using the 
#fish_1998 data
# %>% is the way that we tell the computer what data we are drawing from
fish_1998 %>%
#ggplot is the function that we are using to create a plot. aes() is used to tell ggplot #what we want to see on each axis, in this case x= length and y= mercury.
  ggplot(aes(x = length, y = mercury)) +
#Since ggplot is just a function to create plots, we need to further specify
#what kind of plot it should create. We can do this by using the geom_point
#function. Because we are making a scatter plot, we use the function geom_point().
#We can also add a few more parameters to the graph, such as changing the color
#of the points (color = 'blue), or the size of them (size [2]).
  geom_point(color = 'blue', size = 2) +
#We can also add shapes to the plot. Here we added a dashed line to show where 
#the EPA's guideline for unsafe levels of mercury in fish would fall. To create 
#this we used the geom_hline function which simply creates a horizontal line at
#a y-intercept that you set. We can also adjust the color and appearance of the 
#line with linetype and color.
  geom_hline(yintercept = 4.5, linetype= "dashed", color = 'red')
```


```{r}
# For this plot, we want to see the distributions of lengths across the fish and how many #of them are above 60 cm. We'll start with a very similar order of steps as the scatterplot #we just made.
fish_1998 %>%
  ggplot(aes(y=length, x= "fish"))+
# x="fish" indicates that the x axis doesn't have a variable and is titled fish. This #allows us to look at the variation in lengths of fish independent of another variable.
  geom_hline(yintercept = 50, color= "red")+
  geom_jitter()
# the jitter plot is a variation on the scatterplot, but it separates the data so that we #can distinguish how many points are above 60 cm. To see the difference, try geom_point () #and then geom_jitter ()!
```

--------------------------------------------------------------------------------

#DAY 2: 

We will now analyze data collected from the same monitoring sites in the K'avi 
community from 25 years later (2023). In light of data collected in 1998, efforts were 
made to clean up the heavy metals present in the water that were becoming concentrated
in the local fish populations. 

Our goal today is to see whether the efforts made by tribal fishery managers were 
effective in reducing the amount of mercury present in the fish. 

# PART 1: Loading in and exploring the data

Like we did on Day 1 of the fish module, we first need to load in our datasets!


## First, we check and set our working directory. First we will use the getwd()
command to figure out which working directory we are currently in. Then we will 
use "setwd()" to change our working directory to the directory where our data lives.
The easiest way to think of a directory is as a location on your computer where 
data and other files are located. Each of these directories can be accessed with 
their own unique file path, which is basically a list of different locations on 
your computer that becomes more specific as it continues! 
```{r set wd}
getwd()
setwd()
list.files()
```


## Load in packages 

We will be using the same packages as we used on Day 1. Remember to load packages, 
we used the command library(), with the name of the package in the parentheses. 

```{r load packages}
library(tidyverse)
library(dplyr)
library(ggplot2)
```
#Troubleshoot: If that didn't work, it might be because you don't already have 
#these packages installed. To install them, copy this code: install.packages("tidyverse") 
#above the line library(tidyverse), and see if that works. 


## Now we will load in the dataset for the physical fish data

```{r fish}
fish <- read.csv("fish_2023.csv", header = TRUE, sep = ',')
```

Let's break down the different parts of what just happened:
1) We told R to read the data (a .csv file) using the command read.csv()
2) Within the (""), we identify the data file from our working directory that we want to load into R
3) header = TRUE just tells R that the first row of data is the column names. The alternative is header = FALSE
4) sep is short for the word "separate", and it tells R that each column in the csv is separated by a comma ','
3) "fish" is the name we are giving that file in R, and is how we will refer to this data going forward.
4) <- is like = in a math equation, it tells R that "fish" is the same as the data "fish_1998.csv"

## Viewing the data
```{View data pt. 1}
View(fish_2) 
```

## Different way to view the data
``` {View data pt. 2}
head(fish_2) #just shows the column names and the first few rows of the data
```

What data do we have? What sort of questions can we ask with this data?

## Exploring the dimensions of the data

```{r explore data dimensions}
dim(fish_2) #shows the dimensions of the dataset, which will be important later on
```


# PART 2: Running some basic statistics! 

According to the EPA, the maximum safe level of mercury to be consumed is around
0.1 mg/kg/day. Tribal fishery managers are interested in how mercury levels in 
fish belly fat have changed since 1998 to 2023, now that the rivers have been 
cleaned

Below, we will analyze data points from the "fish_2" data set to try and answer 
these questions. 


## What is the mean amount of mercury found in fish across all sites in 2023? 

```{r mean amount of mercury}
mean(fish_2$mercury_2023)
#you can see that $ is how you tell R what variable/column you want to work with
```


## What is the median amount of mercury found in fish in 2023?

```{r median amount of mercury}
median(fish_2$mercury_2023)
```

#How would we interpret these median and mean values? How do these values compare from 
the values we generated last class using the "fish" data from 1998? 



## Now figure out what the maximum and minimum amount of mercury was found in fish
in 2023:
``` {r max and minimum amount of mercury}


```
 
 
# PART 3: In order to best visualize how mercury levels in fish have been affected
by the waterway clean up, tribal fishery managers believe that making a graph 
will be the most effective. 

We'll practice using ggplot again to visualize fish 
data from the fish_2023 dataset, and compare our results to those we generated 
with the fish_1998 dataset. 

## Recall from last class the steps to make a plot with ggplot:
```{r ggplot, Scatter Plot}

#First we will tell ggplot which dataframe we are pulling from, in this case 
#it would be fish_2023, so we would write the name of the dataframe, followed by
#%>%
fish_2023 %>%
#Next we will call "ggplot" followed by the "aes() argument. Which data would 
  #go on the x and y axis? 
  ggplot(aes(x = , y = ) +
#Now it's time to specify which plot we want ggplot to make. A scatterplot
#would be good to visualize our data, so we will call "geom_point()". In the 
#parentheses, we can specify extra details about how we want the graph to appear.
#Here, we will set the color to green, and the size of the points to 2. 
  geom_point(color = 'green', size = 2) +
#To truly understand if efforts to clean up the waterways made a difference in 
#mercury concentrations in the fish, we will again place a dashed line on the 
#graph where the EPA deems the unsafe level of mercury in fish would be. We will
#do this by calling geom_hline, then setting the y-intercept of where we want the
#line to be placed, set the "linetype" and set the "color" of the line. 
geom_hline(yintercept = 4.5, linetype= "dashed", color = 'red')
```


##INTERPRETATION: Based on the distribution of data in our plot from the fish_2023
dataset compared to how our plot looked with the fish_1998 dataset, were the clean-up
efforts successful? If so, how can you tell? 